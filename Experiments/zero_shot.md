## Zero-shot Prompting

### Prompt Used
The model was given the puzzle description and asked to find any valid
sequence of transitions that reduces the initial string to empty.

#### The exact prompt given was:
You are given a string rewriting puzzle.
Initial string:

<I have kept the string here>
Available transitions:

Each transition replaces ALL occurrences of src with tgt.
Transitions (indexed):

0. "src1"->"tgt1"
1. "src2" -> "tgt2"
....so on <I have replaced the real transitions here>
Your task:
Return ANY sequence of transition indices that reduces the initial string

to an empty string.
Rules:

Transitions can be reused.
The goal is not to minimize steps.
Return only a JSON object in the following format:

{
  "solution": [index1, index2, ...]
}



### Experimental Setup
Evaluated zero-shot prompting on a small but diverse subset of puzzles:
- 3 easy puzzles (auto-generated)
- 5 medium puzzles (auto-generated)
- 3 hard puzzles (manually curated, adversarial, since hard puzzles autogenerated weree just lengthy, but not that hard)

Each puzzle was attempted exactly once. No retries or corrections were done.

---

### Quantitative Results

| Difficulty | Solved | Total |
|----------|--------|-------|
| Easy     | 3      | 3     |
| Medium   | 3      | 4     |
| Hard    | 0      | 3     |


- Zero-shot prompting performs reliably on easy puzzles with linear monotonic solution paths.
- Performance remains strong on most medium puzzles; however, failures begin to emerge when transitions interact non-trivially.
- Zero-shot prompting fails consistently on manually curated hard puzzles.

---

### Failure Modes

The dominant failure mode across medium and hard puzzles is incorrect application of transitions due to loss of state awareness.

Common patterns include:
- Applying a transition whose precondition was invalidated by an earlier step.
- Planning sequences that appear locally correct but are globally inconsistent.
- Failing to account for non-monotonic effects of transitions that expand or restructure the string.

In hard puzzles, the model often commits to an early plan and does not
recover when intermediate steps invalidate later transitions.

---

### Key Insight

Zero-shot prompting reveals that while LLMs can handle surface-level string rewriting, they struggle with maintaining global state consistency and respecting action preconditions in adversarial settings.

