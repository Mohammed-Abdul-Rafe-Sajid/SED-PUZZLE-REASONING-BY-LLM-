# Constarint Aware State Verification (CASV) Prompting
For the creative part, I have chosen the CASV prompting, because majority of  the failures were due to non applicability of transitions, and hallucination for finding the correct solution.
This would force the model to explicitly verify applicability of each transition before applying it, and to stop immediately if no valid move exists.

### (Read Key Insight at the bottom to get an idea of results)

## Prompt Used
The model was instructed to explicitly enumerate applicable transitions at each step and only apply transitions whose source substrings were present in the current string.

- The exact prompt given was:
You are given a string rewriting puzzle.

Initial string:
<INITIAL_STRING>

Transitions (indexed):
0: src -> tgt
1: src -> tgt
2: src -> tgt
...

Task:
Find a sequence of transitions that reduces the initial string to the empty string.

Special Instructions:
- At each step, list all transitions whose src is currently present in the string.
- Choose one valid transition from that list.
- Apply it and update the string.
- If no transition is applicable at any step, explicitly state that and stop.

At the end, output only the final solution in this JSON format:

{
  "solution": [index1, index2, ...]
}


## Experimental Setup

We evaluated the constraint-aware prompt on a small but focused set of puzzles:
- one medium-difficulty puzzle generated by the script, and  
- four manually designed hard puzzles intended to be adversarial.

For each puzzle, we tested the same prompt on both Gemini (web) and GPT (web) to allow a direct comparison under identical conditions.

---

## Quantitative Results

| Model  | Hard puzzles solved | Total |
|--------|---------------------|-------|
| Gemini | 3                   | 4     |
| GPT    | 0                   | 4     |

---

## Observations

The constraint-aware prompt leads to a clear improvement on hard puzzles for Gemini. In several cases, Gemini is able to maintain valid transition sequences over longer horizons and successfully reach the empty string.

GPT, on the other hand, struggles to benefit from the same prompt. It often fails early by either returning an empty solution or by confusing similar
transition patterns (for example, reversing `TK` and `KT`).

Compared to Chain-of-Thought prompting, the constraint-aware prompt reduces
random or hallucinated steps while still allowing deeper reasoning for models that can follow the constraints reliably. More importantly, this prompt is a big success over COT or few shot, as it solves manually curated hard puzzles which the former could not.

---

## Failure Modes

Even with constraint-aware prompting, some failure patterns remain:
- the model occasionally applies an invalid transition late in the solution after several correct steps,
- similar substrings are sometimes confused, leading to subtle but fatal errors,
- in some cases, the model stops with a non-empty string despite valid transitions still being available, and there was a possibility that it would later reach the solution.

---

## Key Insight

Explicitly instructing the model to check transition applicability can significantly improve performance on adversarial puzzles, but the effect seen is highly model-dependent. 
While this strategy helps models like Gemini reason more
carefully, it does not fully address deeper issues such as global planning and recovery from early mistakes.
